// EDES-U1.4 - Traductores
// Banco de preguntas sobre compiladores, intérpretes y traductores
// CE 1.4 - Tipos de traductores y proceso de compilación

::CE 1.4 – Compilación AOT para videojuego::
Estás desarrollando un videojuego AAA en C++ que requiere máximo rendimiento. El equipo debate si usar compilación AOT o interpretación. ¿Qué ventaja ofrece la compilación AOT en este escenario?
{
=El código se traduce completamente a instrucciones máquina nativas antes de ejecutar, permitiendo optimizaciones agresivas y rendimiento máximo sin overhead de interpretación. #Correcto\: Compilación AOT (Ahead-Of-Time) para videojuegos\: (1) PROCESO\: g++ -O3 juego.cpp → juego.exe (código máquina x86/ARM nativo). (2) OPTIMIZACIONES\: Loop unrolling, vectorización SIMD, inline agresivo, eliminación código muerto, optimizaciones específicas de CPU. (3) EJECUCIÓN\: El .exe contiene instrucciones directas de CPU, sin intérprete, sin VM, sin overhead. (4) RENDIMIENTO\: Crítico para videojuegos AAA donde cada frame cuenta (60+ FPS). El compilador tiene TODO el tiempo del mundo para optimizar antes de distribuir. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%La interpretación es mejor porque permite modificar el código del juego en tiempo real sin recompilar. #Incorrecto\: Aunque la interpretación permite modificación dinámica, el COSTO de rendimiento es INACEPTABLE para videojuegos AAA\: • Interpretación\: Lee código, traduce a acciones, ejecuta (overhead significativo). • Videojuegos AAA necesitan\: Renderizar millones de polígonos, física compleja, IA, audio, red, TODO a 60+ FPS. • Incluso con JIT, el warm-up y overhead serían problemáticos. • La modificación dinámica NO vale la pérdida de 50-90% de rendimiento. Los estudios AAA usan C++ compilado AOT por rendimiento. Algunos usan scripting interpretado (Lua/Python) solo para LÓGICA de juego, no motor. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%AOT genera bytecode portable que funciona en todas las plataformas de consolas sin cambios. #Incorrecto\: CONFUSIÓN con máquinas virtuales. AOT NO genera bytecode portable\: • AOT\: Compilación a código NATIVO específico de plataforma (PlayStation→ARM, Xbox→x86-64, PC→x86-64/ARM). • Bytecode portable\: Es lo que genera Java/C#, NO C++ con AOT. • Para consolas, DEBES compilar separadamente\: PlayStation build, Xbox build, PC build (arquitecturas diferentes). • La ventaja de AOT NO es portabilidad; es RENDIMIENTO máximo. Sacrificas portabilidad (código fuente portable, binarios no) a cambio de velocidad extrema. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%AOT permite al juego ejecutarse sin sistema operativo directamente en el hardware de la consola. #Incorrecto\: PARCIALMENTE CIERTO pero NO es la ventaja principal. Aunque videojuegos consola SÍ ejecutan "cerca del metal"\: (1) Las consolas TIENEN un SO ligero (FreeBSD modificado en PS, Windows modificado en Xbox). (2) AOT permite código nativo que el SO de consola carga y ejecuta directamente. (3) Pero esto NO es exclusivo de AOT; cualquier código compilado hace esto. La ventaja REAL de AOT vs interpretación es RENDIMIENTO (código optimizado nativo), NO la ausencia de SO. El SO sigue existiendo en consolas. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
}

::CE 1.4 – Interpretación para scripting web::
Desarrollas un servidor web Node.js que ejecuta JavaScript del lado servidor. ¿Por qué JavaScript usa interpretación (con JIT) en lugar de compilación AOT como C?
{
=Permite ejecución inmediata del código fuente sin pasos de compilación separados, facilitando desarrollo rápido, despliegue dinámico y modificación de código en caliente. #Correcto\: Ventajas de interpretación para JavaScript/Node.js\: (1) DESARROLLO\: Editas código.js → refrescas → cambios inmediatos. Sin compilación lenta. (2) DESPLIEGUE\: Subes archivos .js al servidor → funcionan inmediatamente. Sin build process. (3) DINÁMICO\: eval(), require() dinámico, código generado en runtime. (4) JIT MODERNO\: V8 (motor de Node.js) compila JIT a código nativo → rendimiento cercano a compilado. (5) PRODUCTIVIDAD\: Ciclo edit-run instantáneo vs edit-compile-link-run de C++. Para servidores web (I/O bound más que CPU bound), la velocidad de desarrollo vale más que el último 10% de rendimiento. Consulta `EDES-U1.4.-Traductores.md`, sección '2. Interpretación y lenguajes interpretados'.
~%-33.3333%JavaScript no puede compilarse a código nativo bajo ninguna circunstancia por limitaciones del lenguaje. #Incorrecto\: FALSO. JavaScript SÍ puede compilarse a código nativo\: • V8 (motor Node.js/Chrome)\: Usa JIT para compilar JavaScript → código máquina en runtime. • Hermes (React Native)\: Compila JavaScript a bytecode ahead-of-time. • QuickJS\: Puede compilar JavaScript a ejecutables nativos. • WebAssembly\: JavaScript puede compilar WASM a código nativo. La RAZÓN de interpretación es DISEÑO y CONVENIENCIA, NO imposibilidad técnica. JavaScript fue diseñado para ejecución inmediata en navegadores, no compilación previa. Consulta `EDES-U1.4.-Traductores.md`, sección '2. Interpretación y lenguajes interpretados'.
~%-33.3333%La interpretación es más rápida que compilación AOT porque evita la fase de compilación. #Incorrecto\: CONFUNDE desarrollo vs ejecución. DESARROLLAR es más rápido con interpretación (sin esperar compilación), pero EJECUTAR es más lento\: • Interpretación pura\: Lee código fuente, traduce, ejecuta (overhead en cada ejecución). • AOT\: Compilación lenta UNA VEZ, ejecución rápida SIEMPRE. • JIT (híbrido)\: Compila en primera ejecución, optimiza con datos reales. • Para Node.js, el trade-off es\: Desarrollo ágil + rendimiento "suficientemente bueno" con JIT > Rendimiento máximo con AOT. La interpretación NO es más rápida en ejecución; es más rápida en desarrollo. Consulta `EDES-U1.4.-Traductores.md`, sección '2. Interpretación y lenguajes interpretados'.
~%-33.3333%JavaScript interpretado consume menos memoria que código compilado porque no genera archivos binarios. #Incorrecto\: FALSO. Interpretación puede consumir MÁS memoria\: • Interpretación\: Mantiene código fuente en memoria + estructuras AST + bytecode + datos del intérprete. • Compilado AOT\: Solo código máquina (compacto) + datos. • JIT (Node.js/V8)\: Código fuente + bytecode + código máquina generado JIT + metadata de optimización → MUCHO más que solo binario. Node.js es notorio por uso alto de RAM comparado con lenguajes compilados. La ventaja NO es memoria; es flexibilidad y velocidad de desarrollo. Consulta `EDES-U1.4.-Traductores.md`, sección '2. Interpretación y lenguajes interpretados'.
}

::CE 1.4 – Compilador JIT en acción::
Tu aplicación Java corre en un servidor 24/7 procesando transacciones. Notas que después de una hora, el throughput aumenta un 30% sin cambios en el código. ¿Qué está ocurriendo?
{
=El compilador JIT de la JVM detectó métodos "calientes" (ejecutados frecuentemente) y los recompiló a código máquina nativo optimizado, mejorando el rendimiento. #Correcto\: Proceso JIT detallado\: (1) INICIO\: JVM interpreta bytecode (lento pero arranque rápido). (2) PROFILING\: Cuenta ejecuciones de cada método (invocation counter). (3) THRESHOLD\: Cuando método se ejecuta >N veces (ej. 10000), se marca "hot". (4) COMPILACIÓN C1\: Compilador JIT C1 (client) genera código nativo con optimizaciones ligeras (rápido). (5) COMPILACIÓN C2\: Compilador C2 (server) recompila con optimizaciones agresivas\: inline, especialización, eliminación código muerto. (6) RESULTADO\: Código crítico ejecuta a velocidad nativa. El 30% de mejora es típico después de warm-up JIT. Consulta `EDES-U1.4.-Traductores.md`, sección '3. Compilación en tiempo de ejecución'.
~%-33.3333%El sistema operativo optimizó la asignación de memoria automáticamente después de analizar patrones de uso. #Incorrecto\: El SO hace gestión de memoria, pero NO explica mejora tan significativa y consistente\: • El SO gestiona\: paginación, swap, caché de disco (continuo, no "después de 1 hora"). • Una mejora de 30% de throughput NO viene de optimización de SO. • Si fuera SO, afectaría a TODAS las aplicaciones, no solo Java. El patrón de "mejora gradual en primera hora" es CARACTERÍSTICO de JIT warm-up. Experimentos\: (1) -Xint (solo interpretación)\: NO hay mejora. (2) -Xcomp (compilar todo al inicio)\: Rendimiento bueno desde el principio, pero sin optimizaciones basadas en datos reales. El JIT es la causa. Consulta `EDES-U1.4.-Traductores.md`, sección '3. Compilación en tiempo de ejecución'.
~%-33.3333%La JVM está descargando trabajo a la GPU después de la primera hora de análisis de carga. #Incorrecto\: FALSO. La JVM estándar NO descarga automáticamente a GPU\: • La GPU se usa para\: gráficos, cómputo paralelo (CUDA/OpenCL), aprendizaje automático. • La JVM NO migra código arbitrario a GPU automáticamente (requiere APIs específicas\: JOCL, Aparapi). • Procesar transacciones (lógica de negocio, base de datos, red) NO es paralelizable en GPU. • La mejora de 30% viene de JIT compilando bytecode → código CPU nativo optimizado, NO de GPU. Esta respuesta confunde JIT con computación heterogénea (CPU+GPU). Consulta `EDES-U1.4.-Traductores.md`, sección '3. Compilación en tiempo de ejecución'.
~%-33.3333%El garbage collector mejora después de aprender los patrones de creación de objetos. #Incorrecto\: Aunque el GC SÍ tiene adaptación, NO causa mejoras de 30% tan claras\: • GC moderno (G1, ZGC, Shenandoah)\: Adapta tamaños de generaciones, ajusta pausas. • Mejoras de GC\: Típicamente reducción de pausas (latencia), no tanto aumento de throughput. • Una mejora de throughput de 30% es DEMASIADO para ser solo GC. El JIT compilation es el factor DOMINANTE en mejora de rendimiento de aplicaciones Java long-running. GC contribuye, pero el JIT es la causa principal. Experimento\: Medir con -XX\:+PrintCompilation muestra compilaciones JIT correlacionadas con mejora de rendimiento. Consulta `EDES-U1.4.-Traductores.md`, sección '3. Compilación en tiempo de ejecución'.
}

::CE 1.4 – Transpilador TypeScript a JavaScript::
Tu equipo de frontend usa TypeScript pero los navegadores solo ejecutan JavaScript. ¿Qué hace el transpilador TypeScript (tsc) en este proceso?
{
=Convierte código fuente TypeScript (con tipos estáticos) a código fuente JavaScript (sin tipos), permitiendo que el navegador ejecute el resultado. #Correcto\: Proceso de transpilación TypeScript\: (1) ENTRADA\: archivo.ts con TypeScript (tipos estáticos, interfaces, genéricos, etc.). (2) VERIFICACIÓN DE TIPOS\: tsc comprueba que los tipos sean correctos (errores en tiempo de compilación). (3) TRANSPILACIÓN\: tsc genera archivo.js ELIMINANDO los tipos (JavaScript no los entiende). (4) SALIDA\: JavaScript estándar que cualquier navegador ejecuta. (5) VENTAJA\: Seguridad de tipos en desarrollo + compatibilidad con navegadores. TypeScript es un SUPERSET de JavaScript\: todo JS válido es TS válido, pero TS añade tipos. El transpilador "borra" los tipos. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%Compila TypeScript directamente a bytecode que el navegador ejecuta más rápido que JavaScript. #Incorrecto\: FALSO. Los navegadores NO ejecutan bytecode de TypeScript\: • Navegadores ejecutan\: JavaScript (interpretado/compilado JIT por motor V8/SpiderMonkey/JavaScriptCore). • TypeScript NO genera bytecode; genera JavaScript (código fuente). • El proceso es\: TypeScript → (transpilación) → JavaScript → (navegador compila JIT) → código máquina. • El rendimiento del JavaScript generado es IDÉNTICO a si escribieras JavaScript manualmente. TypeScript NO es más rápido en ejecución; es más SEGURO en desarrollo (detecta errores de tipos). Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%Interpreta TypeScript directamente en el navegador sin necesidad de convertirlo a JavaScript. #Incorrecto\: FALSO. Los navegadores NO entienden TypeScript nativamente\: • Los navegadores solo ejecutan\: JavaScript, WebAssembly. • NO hay motor TypeScript en navegadores. • DEBES transpilar TS → JS ANTES de cargar en el navegador. • Workflow típico\: (1) Desarrollo\: Escribes .ts. (2) Build\: tsc genera .js. (3) Despliegue\: Subes .js al servidor. (4) Navegador\: Descarga y ejecuta .js (NO .ts). Algunos bundlers (webpack + ts-loader) pueden hacer esto transparentemente, pero SIEMPRE hay transpilación TS→JS. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%Convierte JavaScript a TypeScript para añadir tipos automáticamente al código existente. #Incorrecto\: AL REVÉS. TypeScript → JavaScript, NO JavaScript → TypeScript\: • Transpilación es\: TypeScript (con tipos) → JavaScript (sin tipos). • Convertir JavaScript → TypeScript (añadir tipos) es POSIBLE pero\: (1) Requiere herramientas diferentes (no tsc, sino análisis estático). (2) Los tipos serían inferidos/adivinados, no garantizados correctos. (3) NO es lo que hace el transpilador tsc. tsc hace lo contrario\: ELIMINA tipos. Puedes migrar código JS a TS manualmente (renombrar .js→.ts y añadir tipos gradualmente), pero no es transpilación automática. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
}

::CE 1.4 – Análisis léxico en compilación::
Un compilador de C está procesando el código "int suma = a + b;". ¿Qué hace la fase de análisis léxico con esta línea?
{
=Divide el texto en tokens\: 'int' (keyword), 'suma' (identifier), '=' (operator), 'a' (identifier), '+' (operator), 'b' (identifier), ';' (delimiter). #Correcto\: Análisis léxico (Lexer/Scanner)\: (1) ENTRADA\: Secuencia de caracteres (texto del código). (2) PROCESO\: Agrupa caracteres en TOKENS (unidades con significado)\: • 'int'\: KEYWORD (palabra reservada del lenguaje). • 'suma'\: IDENTIFIER (nombre de variable). • '='\: OPERATOR (asignación). • 'a', 'b'\: IDENTIFIER. • '+'\: OPERATOR (suma). • ';'\: DELIMITER (fin de sentencia). (3) SALIDA\: Secuencia de tokens que alimenta el análisis sintáctico. (4) ELIMINA\: Espacios, comentarios (irrelevantes para sintaxis). El lexer NO entiende significado; solo clasifica. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Verifica que las variables 'a' y 'b' estén declaradas antes de usarse en la expresión. #Incorrecto\: Eso es ANÁLISIS SEMÁNTICO, NO léxico. Las fases del compilador\: (1) LÉXICO\: Divide texto en tokens (no entiende variables, tipos, declaraciones). (2) SINTÁCTICO\: Construye AST (verifica gramática\: "int X = Y;" es válido). (3) SEMÁNTICO\: Verifica SIGNIFICADO\: variables declaradas, tipos compatibles, scope correcto. En análisis léxico, el compilador NO sabe que 'a' y 'b' son variables ni si están declaradas. Solo sabe que son "identificadores" (tokens de tipo IDENTIFIER). La verificación de declaración viene DESPUÉS. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Genera el código máquina correspondiente a la operación de suma de 'a' y 'b'. #Incorrecto\: Eso es GENERACIÓN DE CÓDIGO, la ÚLTIMA fase, NO léxico. Orden de fases\: (1) LÉXICO\: texto → tokens. (2) SINTÁCTICO\: tokens → AST. (3) SEMÁNTICO\: AST → AST anotado (con tipos, símbolos). (4) GENERACIÓN CÓDIGO INTERMEDIO\: AST → IR. (5) OPTIMIZACIÓN\: IR → IR optimizado. (6) GENERACIÓN CÓDIGO MÁQUINA\: IR → assembly/binario. El análisis léxico es la PRIMERA fase; solo tokeniza. No genera código máquina (eso sería saltar todas las fases intermedias). Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Construye el árbol de sintaxis abstracta (AST) representando la estructura de la declaración. #Incorrecto\: Eso es ANÁLISIS SINTÁCTICO (Parser), NO léxico. Diferencia\: • ANÁLISIS LÉXICO\: texto → lista plana de tokens (secuencial). Ejemplo\: ['int', 'suma', '=', 'a', '+', 'b', ';']. • ANÁLISIS SINTÁCTICO\: tokens → árbol AST (jerárquico). Ejemplo\: Declaration(type=int, name=suma, init=BinaryOp(left=a, op=+, right=b)). El lexer produce entrada para el parser; el parser construye el AST. El lexer NO entiende estructura; solo clasifica tokens. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
}

::CE 1.4 – Análisis sintáctico con error::
Compilas código C con la línea "int x = (5 + 3;". El compilador da error en análisis sintáctico. ¿Qué detectó?
{
=Falta el paréntesis de cierre ')' antes del punto y coma, violando la gramática del lenguaje que requiere paréntesis balanceados. #Correcto\: Análisis sintáctico (Parser)\: (1) ENTRADA\: Secuencia de tokens del lexer\: ['int', 'x', '=', '(', '5', '+', '3', ';']. (2) PROCESO\: Construye AST según GRAMÁTICA del lenguaje C. (3) GRAMÁTICA espera\: expresión entre paréntesis debe tener '(' y ')' balanceados. (4) ERROR DETECTADO\: '(' sin ')' correspondiente. (5) MENSAJE\: "syntax error\: expected ')' before ';'". El parser verifica ESTRUCTURA del código (gramática), NO significado. Detecta errores como\: paréntesis desbalanceados, falta punto y coma, orden incorrecto de tokens. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%La variable 'x' no está declarada previamente, causando un error de referencia. #Incorrecto\: ESO sería error SEMÁNTICO, y además la línea SÍ declara 'x'\: • "int x = ..." ES una declaración de variable (tipo int, nombre x). • Si el problema fuera "x no declarado", sería usar 'x' SIN declararla antes (ej. "x = 5;" sin "int x" previo). • Ese error se detecta en ANÁLISIS SEMÁNTICO (tabla de símbolos), NO sintáctico. El error REAL es sintáctico\: paréntesis desbalanceados. El parser detecta estructura incorrecta, no significado de variables. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%El valor 5 + 3 debería calcularse antes de asignar, pero el compilador no puede hacerlo. #Incorrecto\: CONFUSIÓN múltiple\: (1) Los compiladores SÍ pueden calcular expresiones constantes (constant folding)\: "5+3" → "8" en optimización. (2) Pero NO es un ERROR no hacerlo; es una optimización opcional. (3) El error REAL es sintáctico\: paréntesis desbalanceados "( ... ;" sin ')'. (4) Incluso si el compilador NO optimizara 5+3, generaría código que lo calcula en runtime (sin error). El problema NO es evaluación de expresión; es sintaxis incorrecta. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%El operador '+' no puede usarse entre literales numéricos en C, solo entre variables. #Incorrecto\: TOTALMENTE FALSO. En C (y casi todos los lenguajes)\: • Puedes sumar literales\: "5 + 3" es PERFECTAMENTE válido. • Puedes mezclar literales y variables\: "5 + x", "x + 3", "5 + 3 + x". • El compilador puede optimizar sumas de literales (constant folding). El error REAL es paréntesis desbalanceados. Esta respuesta inventa una restricción inexistente del lenguaje C. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
}

::CE 1.4 – Análisis semántico con error de tipos::
Compilas en Java "String nombre = 42;". El compilador da error. ¿En qué fase se detecta y por qué?
{
=En análisis semántico, porque detecta incompatibilidad de tipos\: intentas asignar un int (42) a una variable de tipo String. #Correcto\: Análisis semántico verifica SIGNIFICADO del código\: (1) SINTAXIS\: "String nombre = 42;" es sintácticamente correcto (estructura válida\: tipo + nombre + '=' + expresión + ';'). (2) TOKENS y AST\: Correctos. (3) SEMÁNTICA\: Verifica TIPOS\: • Variable 'nombre' es tipo String. • Expresión '42' es tipo int. • Regla\: Tipo de expresión debe ser compatible con tipo de variable. • ERROR\: int NO es compatible con String (no hay conversión automática). (4) MENSAJE\: "Type mismatch\: cannot convert from int to String". La verificación de tipos es ANÁLISIS SEMÁNTICO. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%En análisis léxico, porque el lexer detecta que números no pueden asignarse a variables String. #Incorrecto\: El lexer NO entiende tipos ni variables. Análisis léxico solo\: (1) Divide texto en tokens\: ['String', 'nombre', '=', '42', ';']. (2) Clasifica cada token\: 'String' (IDENTIFIER o KEYWORD), 'nombre' (IDENTIFIER), '=' (OPERATOR), '42' (NUMBER_LITERAL), ';' (DELIMITER). (3) NO sabe que 'String' es un tipo ni que '42' es incompatible. El lexer produce tokens sin entender significado. La verificación de tipos ocurre en ANÁLISIS SEMÁNTICO, mucho después del léxico. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%En análisis sintáctico, porque la gramática de Java prohíbe literales numéricos después de '='. #Incorrecto\: FALSO. La gramática de Java SÍ permite literales después de '='\: • "int x = 42;" es PERFECTAMENTE válido. • "String s = \"hola\";" también. • Sintácticamente, "String nombre = 42;" es CORRECTO (estructura\: declaración + asignación). El problema NO es sintáctico (estructura), es SEMÁNTICO (tipos incompatibles). El parser acepta la estructura; el analizador semántico rechaza la combinación de tipos. Sintaxis = estructura; semántica = significado/tipos. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%En generación de código, porque el compilador no puede generar bytecode para asignar int a String. #Incorrecto\: El error se detecta ANTES de generación de código. Orden de fases\: (1) Léxico → tokens. (2) Sintáctico → AST. (3) Semántico → verifica tipos, símbolos (ERROR AQUÍ). (4) Generación código (NUNCA SE ALCANZA si hay errores semánticos). Los compiladores usan "fail-fast"\: detectan errores lo antes posible. Un error de tipos se detecta en semántica, deteniendo la compilación antes de generar código. Nunca llegas a generación de código con errores semánticos. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
}

::CE 1.4 – Estructura del compilador (Frontend vs Backend)::
El compilador GCC puede compilar C, C++ y Fortran para arquitecturas x86, ARM y RISC-V. ¿Cómo logra esta flexibilidad?
{
=Arquitectura modular\: Frontend (específico del lenguaje) genera IR común; Backend (específico de arquitectura) genera código máquina desde IR. #Correcto\: Estructura del compilador moderno\: (1) FRONTEND (N frontends para N lenguajes)\: • Frontend C\: Parsea C → genera IR (Intermediate Representation). • Frontend C++\: Parsea C++ → genera IR. • Frontend Fortran\: Parsea Fortran → genera IR. Todos producen la MISMA IR (GIMPLE en GCC, LLVM IR en Clang). (2) OPTIMIZADOR (compartido)\: Optimiza IR (loop unrolling, inline, etc.) independiente de lenguaje Y arquitectura. (3) BACKEND (M backends para M arquitecturas)\: • Backend x86\: IR → código x86. • Backend ARM\: IR → código ARM. Resultado\: N×M combinaciones con solo N+M módulos (no N×M compiladores separados). Consulta `EDES-U1.4.-Traductores.md`, sección '1.2. Estructura de un Compilador'.
~%-33.3333%GCC reescribe todo el código fuente a un lenguaje universal antes de compilar para cada arquitectura. #Incorrecto\: PARCIALMENTE correcto pero MAL EXPLICADO. GCC NO reescribe a "lenguaje universal" (código fuente)\: • GCC genera REPRESENTACIÓN INTERMEDIA (IR), que es CÓDIGO de bajo nivel (no código fuente). • IR NO es un lenguaje de programación legible; es una estructura interna del compilador (similar a bytecode pero no ejecutable). • El proceso es\: C/C++/Fortran → IR (interno) → código máquina. NO es\: C → UniversalLanguage.c → código máquina. La IR es un formato interno, no un lenguaje de programación. El concepto es correcto (representación común), pero la descripción como "lenguaje universal" es engañosa. Consulta `EDES-U1.4.-Traductores.md`, sección '1.2. Estructura de un Compilador'.
~%-33.3333%Cada combinación lenguaje-arquitectura tiene un compilador separado (GCC tiene 9 compiladores diferentes). #Incorrecto\: INEFICIENTE y NO es cómo funciona GCC. Si fuera así\: • 3 lenguajes × 3 arquitecturas = 9 compiladores completos. • Añadir un nuevo lenguaje requeriría escribir 3 compiladores (para cada arquitectura). • Añadir nueva arquitectura requeriría 3 compiladores (para cada lenguaje). Duplicación masiva de código. GCC usa arquitectura modular (frontend-IR-backend)\: • Añadir lenguaje\: 1 nuevo frontend (genera IR). • Añadir arquitectura\: 1 nuevo backend (lee IR). Resultado\: 3+3=6 módulos, NO 9 compiladores. Mucho más eficiente y mantenible. Consulta `EDES-U1.4.-Traductores.md`, sección '1.2. Estructura de un Compilador'.
~%-33.3333%GCC compila todo a bytecode Java, que luego se ejecuta en JVM para cada arquitectura. #Incorrecto\: TOTALMENTE FALSO. GCC NO genera bytecode Java\: • GCC genera código MÁQUINA NATIVO (binarios ELF, ejecutables). • No hay JVM involucrada en GCC. • La IR interna (GIMPLE) NO es bytecode ejecutable; es formato interno del compilador. • Confusión completa entre\: (1) GCC (compilador nativo)\: C++ → código máquina. (2) javac (compilador Java)\: Java → bytecode → JVM. Son herramientas y modelos completamente diferentes. GCC produce ejecutables nativos, no bytecode. Consulta `EDES-U1.4.-Traductores.md`, sección '1.2. Estructura de un Compilador'.
}

::CE 1.4 – AST (Árbol de Sintaxis Abstracta)::
El parser genera un AST para la expresión "resultado = (a + b) * c;". ¿Qué representa el AST?
{
=Una estructura de árbol jerárquica donde la raíz es 'asignación', con 'resultado' a la izquierda y '*' a la derecha, que tiene '+' (con 'a','b') y 'c' como hijos. #Correcto\: Estructura del AST\: ``` Asignación ├─ izq\: resultado └─ der\: Multiplicación ├─ izq\: Suma │ ├─ izq\: a │ └─ der\: b └─ der\: c ``` El AST\: (1) ABSTRAE sintaxis concreta (sin paréntesis, punto y coma en el árbol). (2) REPRESENTA estructura semántica (precedencia de operadores\: suma antes que multiplicación). (3) JERÁRQUICO\: Nodos internos = operadores; hojas = variables/literales. (4) FACILITA\: Análisis semántico (recorrer árbol verificando tipos), generación de código (traversal del árbol). El AST es la representación interna fundamental del programa durante compilación. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Una lista secuencial de tokens en el orden en que aparecen en el código fuente. #Incorrecto\: Eso es la salida del LEXER, NO del parser. Diferencia\: • LEXER (análisis léxico)\: Produce lista plana de tokens\: ['resultado', '=', '(', 'a', '+', 'b', ')', '*', 'c', ';']. • PARSER (análisis sintáctico)\: Produce árbol jerárquico AST (estructura con relaciones padre-hijo). El AST NO es lista; es ÁRBOL. Captura estructura y precedencia (paréntesis en código → estructura en árbol). La lista de tokens pierde información de estructura; el AST la preserva. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%El código máquina generado para ejecutar la operación en el procesador. #Incorrecto\: El AST es INTERMEDIO, NO código final. Flujo completo\: (1) Código fuente. (2) Tokens (lexer). (3) AST (parser) ← ESTAMOS AQUÍ. (4) AST anotado (análisis semántico). (5) IR (código intermedio). (6) IR optimizado. (7) Código máquina (generación final). El AST está en la fase 3 de ~7 fases. Es una REPRESENTACIÓN abstracta del programa, no código ejecutable. El código máquina viene DESPUÉS, generado A PARTIR del AST. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Una tabla de símbolos con las variables 'resultado', 'a', 'b', 'c' y sus tipos. #Incorrecto\: Eso es la TABLA DE SÍMBOLOS, NO el AST. Son estructuras diferentes\: • AST\: Representa ESTRUCTURA del código (expresiones, sentencias, control flow). Árbol jerárquico de operaciones. • TABLA DE SÍMBOLOS\: Diccionario de identificadores → información (tipo, scope, offset memoria). Estructura plana (tabla/hashmap). AMBOS se usan en compilación\: • AST\: Para generar código. • Tabla símbolos\: Para verificar tipos, resolver referencias. Pero son estructuras separadas con propósitos diferentes. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
}

::CE 1.4 – Optimización de código::
El compilador ve el código "int x = 5 * 10; int y = x + 0;". ¿Qué optimizaciones puede aplicar?
{
=Constant folding (5*10 → 50) y eliminación de operaciones identidad (x+0 → x), generando simplemente "int x = 50; int y = x;". #Correcto\: Optimizaciones aplicadas\: (1) CONSTANT FOLDING\: Evalúa expresiones constantes en tiempo de compilación\: • "5 * 10" → "50" (sin generar código de multiplicación). (2) IDENTITY ELIMINATION\: Elimina operaciones que no cambian valor\: • "x + 0" → "x" (sumar 0 es identidad). (3) CÓDIGO OPTIMIZADO\: "int x = 50; int y = x;" → Solo 2 asignaciones, sin multiplicación ni suma. (4) BENEFICIO\: Código más pequeño, ejecución más rápida (sin operaciones innecesarias). (5) NIVEL\: Optimizaciones básicas (-O1), casi todos los compiladores las hacen. Optimizaciones más avanzadas\: inlining, loop unrolling, vectorización. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%No puede optimizar porque las variables son declaradas separadamente y no se conocen en tiempo de compilación. #Incorrecto\: FALSO. Las variables SÍ se conocen en tiempo de compilación\: • "int x = 5 * 10;" → El compilador VE que 5 y 10 son LITERALES constantes. • NO dependen de input de usuario, runtime, ni nada externo. • El compilador puede evaluar "5 * 10 = 50" durante compilación. • Aunque 'x' sea variable, su INICIALIZADOR es constante → optimizable. Solo NO podría optimizar si fuera "int a = leerEntrada(); int x = 5 * a;" (depende de runtime). Pero con literales, la optimización es trivial. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Puede vectorizar las operaciones usando instrucciones SIMD para calcular x e y en paralelo. #Incorrecto\: EXAGERADO. Vectorización SIMD se usa para\: • Operaciones PARALELAS sobre ARRAYS/vectores de datos. • Ejemplo\: "for(i=0;i<1000;i++) a[i]=b[i]+c[i];" → procesar 4-8 elementos simultáneamente. Para 2 variables escalares independientes ("int x = ...; int y = ...;"), SIMD NO aplica\: (1) Solo hay 2 operaciones (no es loop con muchas iteraciones). (2) No hay paralelismo de datos (x e y son independientes, pero solo UNA instancia de cada). Las optimizaciones aplicables son constant folding e identity elimination, NO vectorización SIMD. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%Puede eliminar completamente las variables x e y si no se usan después, guardando memoria. #Incorrecto\: Eso sería DEAD CODE ELIMINATION, pero requiere más contexto. DEPENDE de si x e y se usan después\: • Si x e y NO se usan\: Compilador elimina todo el código (dead code). • Si x e y SÍ se usan\: Compilador optimiza las asignaciones (constant folding, identity elimination) pero MANTIENE las variables. La pregunta no especifica si se usan después. Las optimizaciones CIERTAS son constant folding y identity elimination (aplicables independientemente de uso posterior). Dead code elimination es POSIBLE pero requiere analizar el código completo, no solo estas 2 líneas. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
}


::CE 1.4 – Transpilador Kotlin a JavaScript::
Tu equipo desarrolla una aplicación web y quiere usar Kotlin en lugar de JavaScript en el frontend. ¿Cómo funciona Kotlin/JS en este escenario?
{
=El compilador Kotlin/JS transpila código Kotlin a JavaScript que el navegador puede ejecutar, manteniendo la lógica pero generando sintaxis JS. #Correcto\: Proceso Kotlin/JS\: (1) DESARROLLO\: Escribes código en Kotlin (.kt)\: tipos estáticos, null-safety, clases, funciones de orden superior. (2) TRANSPILACIÓN\: kotlinc-js compila Kotlin → JavaScript (.js)\: • NO es compilación a bytecode. • NO es ejecución en VM. • Es traducción fuente-a-fuente (source-to-source compilation = transpilación). (3) SALIDA\: JavaScript estándar que navegadores ejecutan. (4) VENTAJA\: Desarrollas con features modernas de Kotlin, ejecutas en cualquier navegador. (5) SIMILAR A\: TypeScript→JS, CoffeeScript→JS, Dart→JS. El navegador solo ve JavaScript normal. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%Kotlin/JS compila a bytecode de JVM que un plugin de navegador ejecuta como Java applets. #Incorrecto\: FALSO y ANTICUADO. Kotlin/JS NO usa JVM en navegadores\: • Kotlin/JVM\: Compila a bytecode JVM para backend (servidor). • Kotlin/JS\: Transpila a JavaScript para frontend (navegador). • Los navegadores NO ejecutan bytecode JVM (los Java Applets murieron hace años por seguridad). • NO hay plugin JVM en navegadores modernos. Kotlin/JS genera JavaScript puro que el motor JS del navegador (V8, SpiderMonkey) ejecuta. Es transpilación a JS, NO bytecode JVM. Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%El navegador descarga e instala automáticamente el runtime de Kotlin cuando carga la página. #Incorrecto\: NO hay "runtime de Kotlin" separado en Kotlin/JS\: • El código Kotlin transpilado a JavaScript INCLUYE lo necesario de la biblioteca estándar Kotlin (inline en el .js generado). • El navegador ejecuta JavaScript puro, sin runtime especial. • NO se descarga nada adicional (a menos que uses bibliotecas Kotlin extras, que también se transpilan a JS). • Similar a TypeScript\: no hay "runtime TypeScript" en navegadores; todo se convierte a JS. El JavaScript generado es autocontenido (puede ser grande si incluye mucha std lib Kotlin, pero es JS normal). Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
~%-33.3333%Kotlin/JS genera WebAssembly binario que es más rápido que JavaScript en navegadores. #Incorrecto\: CONFUSIÓN. Kotlin/JS NO genera WebAssembly\: • Kotlin/JS → JavaScript (transpilación fuente-a-fuente). • Kotlin/Native → Puede generar ejecutables nativos, pero NO está diseñado para Web. • Para WebAssembly, usarías\: Rust, C/C++ (Emscripten), AssemblyScript, o experimentalmente Kotlin/Native-WASM (en desarrollo). El Kotlin/JS mainstream genera JavaScript, NO WASM. El rendimiento es el mismo que JavaScript (porque ES JavaScript). Si quieres WASM desde Kotlin, necesitas Kotlin/Native con soporte experimental WASM (no Kotlin/JS). Consulta `EDES-U1.4.-Traductores.md`, sección '1. Compilación'.
}

::CE 1.4 – Diferencia compilador vs intérprete (ejecución)::
Python (CPython) y C++ usan enfoques diferentes. ¿Cuál es la diferencia clave en cómo el código llega a ejecutarse?
{
=C++ compila a código máquina ANTES de ejecutar (fase separada); Python compila a bytecode y lo interpreta/ejecuta en la misma fase (compilación implícita). #Correcto\: Comparación detallada\: • C++\: (1) DESARROLLO\: Escribes .cpp. (2) COMPILACIÓN (separada)\: g++ programa.cpp → programa.exe (código máquina). (3) EJECUCIÓN (separada)\: ./programa.exe (CPU ejecuta directamente). Fases SEPARADAS\: compila una vez, ejecuta muchas veces. • Python\: (1) DESARROLLO\: Escribes .py. (2) COMPILACIÓN+EJECUCIÓN (juntas)\: python programa.py → compila a bytecode (.pyc en memoria/caché) + ejecuta bytecode. Fases FUSIONADAS\: compila + ejecuta cada vez (aunque cachea .pyc). La diferencia es\: C++ = 2 pasos visibles; Python = 1 paso aparente (2 pasos internos pero transparentes). Consulta `EDES-U1.4.-Traductores.md`, secciones '1. Compilación' y '2. Interpretación y lenguajes interpretados'.
~%-33.3333%C++ siempre interpreta el código fuente línea por línea; Python compila a código máquina nativo. #Incorrecto\: TOTALMENTE AL REVÉS\: • C++\: COMPILADO a código máquina nativo (no interpretado). g++ genera binarios que CPU ejecuta directamente. • Python (CPython)\: COMPILADO a bytecode, luego INTERPRETADO por PVM. NO genera código máquina nativo por defecto (aunque PyPy usa JIT). Esta respuesta invierte completamente los modelos de ambos lenguajes. Es el error opuesto a la realidad. Consulta `EDES-U1.4.-Traductores.md`, secciones '1. Compilación' y '2. Interpretación y lenguajes interpretados'.
~%-33.3333%No hay diferencia real; ambos generan bytecode intermedio ejecutado por una máquina virtual. #Incorrecto\: C++ NO genera bytecode\: • C++\: Compila a código MÁQUINA NATIVO (instrucciones x86/ARM). NO hay máquina virtual. El SO carga el ejecutable y la CPU lo ejecuta directamente. • Python\: SÍ genera bytecode (.pyc) ejecutado por PVM (Python Virtual Machine). C++ y Python usan modelos FUNDAMENTALMENTE diferentes\: • C++\: Fuente → Código nativo → Ejecución directa en CPU. • Python\: Fuente → Bytecode → Ejecución en VM. Afirmar "no hay diferencia" es completamente falso. Consulta `EDES-U1.4.-Traductores.md`, secciones '1. Compilación' y '2. Interpretación y lenguajes interpretados'.
~%-33.3333%C++ requiere JIT compilation en runtime; Python compila todo ahead-of-time antes de ejecutar. #Incorrecto\: AL REVÉS (y mal en ambos casos)\: • C++\: Compila AOT (Ahead-Of-Time) a código nativo. NO usa JIT. El ejecutable está listo para ejecutar sin compilación runtime. • Python (CPython)\: Compila JIT-ish a bytecode (en runtime, aunque cachea). NO es AOT (no generas binarios para distribuir). Aunque PyPy SÍ usa JIT para compilar bytecode → nativo. La afirmación invierte los modelos\: C++ es AOT (no JIT); Python es runtime compilation (no AOT tradicional). Consulta `EDES-U1.4.-Traductores.md`, secciones '1. Compilación' y '2. Interpretación y lenguajes interpretados'.
}

::CE 1.4 – Generación de código intermedio (IR)::
En LLVM (compilador moderno), después del análisis semántico se genera LLVM IR. ¿Por qué usar una representación intermedia en lugar de generar código máquina directamente?
{
=IR permite optimizaciones independientes del lenguaje y arquitectura, y facilita soportar múltiples lenguajes y plataformas con menos duplicación de código. #Correcto\: Ventajas de IR (Intermediate Representation)\: (1) INDEPENDENCIA\: • Frontend (Rust, Swift, C++, etc.) → genera misma IR. • Backend (x86, ARM, RISC-V, etc.) → consume misma IR. (2) OPTIMIZACIÓN CENTRALIZADA\: • Optimizaciones (inline, loop unroll, dead code, etc.) se escriben UNA VEZ sobre IR. • Benefician a TODOS los lenguajes y TODAS las plataformas. (3) MODULARIDAD\: • Añadir lenguaje\: 1 frontend nuevo. • Añadir arquitectura\: 1 backend nuevo. (4) REUTILIZACIÓN\: N lenguajes × M arquitecturas con N+M módulos, NO N×M. LLVM IR es el "lenguaje universal" intermedio del compilador. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%IR es más rápida de ejecutar que código máquina porque está optimizada por el compilador. #Incorrecto\: FALSO. IR NO se ejecuta\: • IR es un formato INTERMEDIO usado DENTRO del compilador. • IR NO es ejecutable; es una representación del programa para análisis y optimización. • El proceso es\: Código fuente → IR → Optimizaciones (sobre IR) → Código máquina (ejecutable). • El código máquina generado DESDE IR optimizada es rápido. • La IR en sí NO se ejecuta (a menos que uses un intérprete de IR, que sería lento). IR es para el compilador, no para ejecución. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%IR es el formato de distribución que se envía a los usuarios, quienes lo compilan localmente. #Incorrecto\: GENERALMENTE NO, aunque hay excepciones\: • Distribución típica\: Código fuente (.c/.cpp/.rs) o ejecutables nativos (.exe). • IR (LLVM IR) NO suele distribuirse a usuarios finales. • Excepciones\: (1) WebAssembly (es una IR que navegadores ejecutan, similar conceptualmente). (2) Android apps pueden incluir LLVM IR para compilación en dispositivo. (3) Bitcode de iOS (LLVM IR) para optimización en App Store. Pero en general (desktop, servidor), NO distribuyes IR; distribuyes fuente o binarios. IR es interna al proceso de compilación. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
~%-33.3333%LLVM genera IR para interpretar el programa en una máquina virtual en lugar de compilar. #Incorrecto\: LLVM NO es un intérprete por defecto\: • LLVM es un COMPILADOR\: LLVM IR → código máquina nativo. • Aunque existe "lli" (LLVM interpreter) que PUEDE interpretar LLVM IR, NO es el uso principal. • Uso típico\: clang programa.c → LLVM IR (interno) → optimizaciones → código máquina x86/ARM. • LLVM NO es como la JVM (que ejecuta bytecode en VM). • LLVM genera ejecutables nativos, NO máquina virtual. LLVM IR es una representación intermedia del compilador, no un bytecode para VM. Consulta `EDES-U1.4.-Traductores.md`, sección '1.1. El proceso de compilación'.
}
